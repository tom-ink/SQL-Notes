{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up BigQuery\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Client > Project > Dataset > Tables\n",
    "# Client objects hold projects and a connection to the BigQuery service.\n",
    "# Project is a collection of datasets.\n",
    "# Dataset is a collection of tables.\n",
    "# Tables are composed of rows and columns.\n",
    "\n",
    "#* Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "#* Construct a reference to the \"hacker_news\" dataset contained within the \"bigquery-public-data\" project \n",
    "dataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n",
    "\n",
    "#* API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "#* List all the tables in the \"hacker_news\" dataset\n",
    "tables = list(client.list_tables(dataset))\n",
    "\n",
    "#* Print names of all tables in the dataset\n",
    "for table in tables:  \n",
    "    print(table.table_id)\n",
    "\n",
    "#* Construct a reference to the \"full\" table\n",
    "table_ref = dataset_ref.table(\"full\")\n",
    "\n",
    "#* API request - fetch the table\n",
    "table = client.get_table(table_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Understanding the table's schema\n",
    "\n",
    "#* Describe the \"full\" table's columns\n",
    "table.schema\n",
    "# Info is displayed in the following order: \n",
    "# name of the column, \n",
    "# field type (or datatype) in the column, \n",
    "# mode of the column ('NULLABLE' means that a column allows NULL values, and is the default), \n",
    "# description of the data in that column.\n",
    "\n",
    "#* Preview the first five row of \"full\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()\n",
    "\n",
    "#* Preview the first five row of \"full\" table's first column\n",
    "client.list_rows(table, selected_fields=table.schema[:1], max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Querying\n",
    "\n",
    "#* Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "#* Note: Arguments pass to FROM and JOIN use backticks (`) and not quotation marks (' or \")\n",
    "#* Arguments are pass within strings, not with semicolon (;)\n",
    "query = \"\"\"\n",
    "        SELECT column1\n",
    "        FROM `project.database.table`\n",
    "        WHERE column2 = 'ABC'\n",
    "        \"\"\"\n",
    "\n",
    "JOIN_query = \"\"\"\n",
    "        SELECT abc.col1, xyz.colB, hta.colII\n",
    "        FROM `project.database.tableABC` AS abc\n",
    "        JOIN `project.database.tableXYZ` AS xyz\n",
    "        ON abc.col0 = xyz.colA\n",
    "        LEFT JOIN `project.database.tableHTA` AS hta\n",
    "        ON abc.col0 = hta.colI\n",
    "        \"\"\"\n",
    "\n",
    "#* Set up the query\n",
    "query_job = client.query(query)\n",
    "\n",
    "#* API request - run the query, and return a pandas DataFrame\n",
    "df1 = query_job.to_dataframe()\n",
    "\n",
    "\n",
    "\n",
    "# ## To estimate the size of any query before running it\n",
    "# # Create a QueryJobConfig object to estimate size of query without running it\n",
    "# dry_run_config = bigquery.QueryJobConfig(dry_run=True)\n",
    "\n",
    "# # API request - dry run query to estimate costs\n",
    "# dry_run_query_job = client.query(query, job_config=dry_run_config)\n",
    "# print(dry_run_query_job.total_bytes_processed)\n",
    "\n",
    "\n",
    "# ## Limiting size of query\n",
    "# # Only run the query if it's less than 1 MB\n",
    "# safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=1000000)\n",
    "\n",
    "# # Set up the query (will only run if it's less than 1 MB)\n",
    "# safe_query_job = client.query(query, job_config=safe_config)\n",
    "\n",
    "# # API request - try to run the query, and return a pandas DataFrame\n",
    "# df1 = safe_query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BigQuery allows for nested columns (column containing dictionaries; RECORD/STRUCT) and multiple values (REPEATED)\n",
    "\n",
    "# Nested data (each row contains a dictionary that can have multiple keys, but each key only has 1 value)\n",
    "#* To select the fields (keys) in nested data: \n",
    "'''\n",
    "SELECT nested_column.field1, nested_column.field2\n",
    "FROM `project.database.table`\n",
    "'''\n",
    "\n",
    "# Repeated data (each row contains an array of values with the same datatype)\n",
    "#* To flatten repeated data:\n",
    "'''\n",
    "SELECT new_column\n",
    "FROM `project.database.table`, UNNEST(nested_column) AS new_column\n",
    "'''\n",
    "\n",
    "# Nested and repeated data (each row contains an array of dictionaries, which may contain nested dictionaries within it)\n",
    "#* To flatten and select the data:\n",
    "'''\n",
    "SELECT nc.field1, nc.field2\n",
    "FROM `project.database.table`, \n",
    "    UNNEST(nested_column) AS nc\n",
    "'''\n",
    "\n",
    "'''\n",
    "SELECT nc.field1.nestedfield1\n",
    "FROM `project.database.table`,\n",
    "    UNNEST(nested_column) AS nc\n",
    "WHERE nc.field2='AAA' AND nc.field3='ABC'\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
